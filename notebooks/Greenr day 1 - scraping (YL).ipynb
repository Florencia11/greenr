{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greenr day 1 - attempting to parse recipe data (YL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T08:07:45.650236Z",
     "start_time": "2020-08-25T08:07:45.211464Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:32:37.467328Z",
     "start_time": "2020-08-24T10:32:37.462328Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_ingredients(section):\n",
    "    \n",
    "    page = requests.get(f'https://www.bbc.co.uk/food/{section}')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    ingredients = []\n",
    "\n",
    "    for a in soup.find_all('a', class_ =\"promo promo__main_course\" ):\n",
    "        npage = requests.get(f'https://www.bbc.co.uk{a[\"href\"]}')\n",
    "        soup = BeautifulSoup(npage.content, 'html.parser')\n",
    "        ingredient = []\n",
    "        for a in soup.find_all('li', class_ = \"recipe-ingredients__list-item\"):\n",
    "            ingredient.append(a.get_text())\n",
    "        \n",
    "        ingredients.append(ingredient)\n",
    "        ingredients = pd.DataFrame(ingredients)\n",
    "        \n",
    "    return ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:32:53.746745Z",
     "start_time": "2020-08-24T10:32:37.683363Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_scraped = get_ingredients('cuisines/mexican')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:32:53.782714Z",
     "start_time": "2020-08-24T10:32:53.762715Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_scraped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYT demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:32:55.446836Z",
     "start_time": "2020-08-24T10:32:53.796713Z"
    }
   },
   "outputs": [],
   "source": [
    "df_nyt = pd.read_csv('https://raw.githubusercontent.com/mtlynch/ingredient-phrase-tagger/master/nyt-ingredients-snapshot-2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:32:55.468876Z",
     "start_time": "2020-08-24T10:32:55.463837Z"
    }
   },
   "outputs": [],
   "source": [
    "df_nyt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:42:57.909250Z",
     "start_time": "2020-08-24T10:42:57.894213Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_nyt.head(10)), df_nyt.head(10).input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:44:09.988778Z",
     "start_time": "2020-08-24T10:44:09.970749Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df_nyt.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:46:00.880495Z",
     "start_time": "2020-08-24T10:46:00.877706Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredient_list = df_nyt.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:45:02.470598Z",
     "start_time": "2020-08-24T10:45:02.466609Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:46:03.228565Z",
     "start_time": "2020-08-24T10:46:03.199505Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredient_counter = Counter(ingredient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:49:26.669184Z",
     "start_time": "2020-08-24T10:49:26.666183Z"
    }
   },
   "outputs": [],
   "source": [
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:49:59.932189Z",
     "start_time": "2020-08-24T10:49:59.926204Z"
    }
   },
   "outputs": [],
   "source": [
    "most_common_ingredients = ingredient_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:51:09.568076Z",
     "start_time": "2020-08-24T10:51:09.559012Z"
    }
   },
   "outputs": [],
   "source": [
    "cPickle.dump(most_common_ingredients, open('ingredients_counts.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:51:12.392639Z",
     "start_time": "2020-08-24T10:51:12.354541Z"
    }
   },
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:51:29.854705Z",
     "start_time": "2020-08-24T10:51:29.848637Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = cPickle.load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:52:20.346486Z",
     "start_time": "2020-08-24T10:52:20.339485Z"
    }
   },
   "outputs": [],
   "source": [
    "var = cPickle.load(open('ingredients_counts.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allrecipes - ingredient names incl. amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T08:08:25.460258Z",
     "start_time": "2020-08-25T08:08:25.435967Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "\n",
    "import re\n",
    "\n",
    "class AllRecipes(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def search(query_dict):\n",
    "        \"\"\"\n",
    "        Search recipes parsing the returned html data.\n",
    "        \"\"\"\n",
    "        base_url = \"https://allrecipes.com/search/results/?\"\n",
    "        query_url = urllib.parse.urlencode(query_dict)\n",
    "\n",
    "        url = base_url + query_url\n",
    "\n",
    "        req = urllib.request.Request(url)\n",
    "        req.add_header('Cookie', 'euConsent=true')\n",
    "\n",
    "        html_content = urllib.request.urlopen(req).read()\n",
    "\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        search_data = []\n",
    "        articles = soup.findAll(\"article\", {\"class\": \"fixed-recipe-card\"})\n",
    "\n",
    "        iterarticles = iter(articles)\n",
    "        next(iterarticles)\n",
    "        for article in iterarticles:\n",
    "            data = {}\n",
    "            try:\n",
    "                data[\"name\"] = article.find(\"h3\", {\"class\": \"fixed-recipe-card__h3\"}).get_text().strip(' \\t\\n\\r')\n",
    "                data[\"description\"] = article.find(\"div\", {\"class\": \"fixed-recipe-card__description\"}).get_text().strip(' \\t\\n\\r')\n",
    "                data[\"url\"] = article.find(\"a\", href=re.compile('^https://www.allrecipes.com/recipe/'))['href']\n",
    "                try:\n",
    "                    data[\"image\"] = article.find(\"a\", href=re.compile('^https://www.allrecipes.com/recipe/')).find(\"img\")[\"data-original-src\"]\n",
    "                except Exception as e1:\n",
    "                    pass\n",
    "                try:\n",
    "                    data[\"rating\"] = float(article.find(\"div\", {\"class\": \"fixed-recipe-card__ratings\"}).find(\"span\")[\"data-ratingstars\"])\n",
    "                except ValueError:\n",
    "                    data[\"rating\"] = None\n",
    "            except Exception as e2:\n",
    "                pass\n",
    "            if data and \"image\" in data:  # Do not include if no image -> its probably an add or something you do not want in your result\n",
    "                search_data.append(data)\n",
    "\n",
    "        return search_data\n",
    "\n",
    "    @staticmethod\n",
    "    def get(url):\n",
    "        \"\"\"\n",
    "        'url' from 'search' method.\n",
    "         ex. \"/recipe/106349/beef-and-spinach-curry/\"\n",
    "        \"\"\"\n",
    "        #base_url = \"https://allrecipes.com/\"\n",
    "        #url = base_url + uri\n",
    "\n",
    "        req = urllib.request.Request(url)\n",
    "        req.add_header('Cookie', 'euConsent=true')\n",
    "\n",
    "        html_content = urllib.request.urlopen(req).read()\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        #try: -- Doesn't currently work\n",
    "        #    rating = float(soup.find(\"div\", {\"class\": \"rating-stars\"})[\"data-ratingstars\"]) -- Doesn't currently work\n",
    "        #except ValueError: -- Doesn't currently work\n",
    "        #    rating = None -- Doesn't currently work\n",
    "        ingredients = soup.findAll(\"li\", {\"class\": \"ingredients-item\"})\n",
    "        steps = soup.findAll(\"span\", {\"class\": \"recipe-directions__list--item\"})\n",
    "        name = soup.find(\"h1\", {\"class\": \"headline heading-content\"}).get_text().replace(\"®\", \"\")\n",
    "\n",
    "        direction_data = soup.find(\"div\", {\"class\": \"directions--section__steps\"})\n",
    "        #prep_time = direction_data.find(\"time\", {\"itemprop\": \"prepTime\"}).get_text() -- Doesn't currently work\n",
    "        #cook_time = direction_data.find(\"time\", {\"itemprop\": \"cookTime\"}).get_text() -- Doesn't currently work\n",
    "        #total_time = direction_data.find(\"time\", {\"itemprop\": \"totalTime\"}).get_text() -- Doesn't currently work\n",
    "\n",
    "        data = {\n",
    "                #\"rating\": rating,\n",
    "                \"ingredients\": [],\n",
    "                \"steps\": [],\n",
    "                \"name\": name\n",
    "                #\"prep_time\": prep_time,\n",
    "                #\"cook_time\": cook_time,\n",
    "                #\"total_time\": total_time\n",
    "                }\n",
    "\n",
    "        for ingredient in ingredients:\n",
    "            str_ing = ingredient.find(\"span\", {\"class\": \"ingredients-item-name\"}).get_text()\n",
    "            if str_ing and str_ing != \"Add all ingredients to list\":\n",
    "                data[\"ingredients\"].append(str_ing.strip())\n",
    "\n",
    "        for step in steps:\n",
    "            str_step = step.get_text()\n",
    "            if str_step:\n",
    "                data[\"steps\"].append(str_step)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T14:58:47.253575Z",
     "start_time": "2020-08-24T14:58:40.570970Z"
    }
   },
   "outputs": [],
   "source": [
    "query_options = {\n",
    "  \"wt\": \"duck curry\",         # Query keywords\n",
    "  \"ingIncl\": \"olives\",        # 'Must be included' ingrdients (optional)\n",
    "  \"ingExcl\": \"onions salad\",  # 'Must not be included' ingredients (optional)\n",
    "  \"sort\": \"re\"                # Sorting options : 're' for relevance, 'ra' for rating, 'p' for popular (optional)\n",
    "}\n",
    "query_result = AllRecipes.search(query_options)\n",
    "\n",
    "# Get :\n",
    "main_recipe_url = query_result[0]['url']\n",
    "detailed_recipe = AllRecipes.get(main_recipe_url)  # Get the details of the first returned recipe (most relevant in our case)\n",
    "\n",
    "# Display result :\n",
    "print(\"## %s :\" % detailed_recipe['name'])  # Name of the recipe\n",
    "\n",
    "for ingredient in detailed_recipe['ingredients']:  # List of ingredients\n",
    "    print(\"- %s\" % ingredient.strip())\n",
    "\n",
    "for step in detailed_recipe['steps']:  # List of cooking steps\n",
    "    print(\"# %s\" % step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Allrecipes - ingredient names only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T13:24:33.945853Z",
     "start_time": "2020-08-24T13:24:33.923808Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "\n",
    "import re\n",
    "\n",
    "class AllRecipes(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def search(query_dict):\n",
    "        \"\"\"\n",
    "        Search recipes parsing the returned html data.\n",
    "        \"\"\"\n",
    "        base_url = \"https://allrecipes.com/search/results/?\"\n",
    "        query_url = urllib.parse.urlencode(query_dict)\n",
    "\n",
    "        url = base_url + query_url\n",
    "\n",
    "        req = urllib.request.Request(url)\n",
    "        req.add_header('Cookie', 'euConsent=true')\n",
    "\n",
    "        html_content = urllib.request.urlopen(req).read()\n",
    "\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        search_data = []\n",
    "        articles = soup.findAll(\"article\", {\"class\": \"fixed-recipe-card\"})\n",
    "\n",
    "        iterarticles = iter(articles)\n",
    "        next(iterarticles)\n",
    "        for article in iterarticles:\n",
    "            data = {}\n",
    "            try:\n",
    "                data[\"name\"] = article.find(\"h3\", {\"class\": \"fixed-recipe-card__h3\"}).get_text().strip(' \\t\\n\\r')\n",
    "                data[\"description\"] = article.find(\"div\", {\"class\": \"fixed-recipe-card__description\"}).get_text().strip(' \\t\\n\\r')\n",
    "                data[\"url\"] = article.find(\"a\", href=re.compile('^https://www.allrecipes.com/recipe/'))['href']\n",
    "                try:\n",
    "                    data[\"image\"] = article.find(\"a\", href=re.compile('^https://www.allrecipes.com/recipe/')).find(\"img\")[\"data-original-src\"]\n",
    "                except Exception as e1:\n",
    "                    pass\n",
    "                try:\n",
    "                    data[\"rating\"] = float(article.find(\"div\", {\"class\": \"fixed-recipe-card__ratings\"}).find(\"span\")[\"data-ratingstars\"])\n",
    "                except ValueError:\n",
    "                    data[\"rating\"] = None\n",
    "            except Exception as e2:\n",
    "                pass\n",
    "            if data and \"image\" in data:  # Do not include if no image -> its probably an add or something you do not want in your result\n",
    "                search_data.append(data)\n",
    "\n",
    "        return search_data\n",
    "\n",
    "    @staticmethod\n",
    "    def get(url):\n",
    "        \"\"\"\n",
    "        'url' from 'search' method.\n",
    "         ex. \"/recipe/106349/beef-and-spinach-curry/\"\n",
    "        \"\"\"\n",
    "        #base_url = \"https://allrecipes.com/\"\n",
    "        #url = base_url + uri\n",
    "\n",
    "        req = urllib.request.Request(url)\n",
    "        req.add_header('Cookie', 'euConsent=true')\n",
    "\n",
    "        html_content = urllib.request.urlopen(req).read()\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        #try: -- Doesn't currently work\n",
    "        #    rating = float(soup.find(\"div\", {\"class\": \"rating-stars\"})[\"data-ratingstars\"]) -- Doesn't currently work\n",
    "        #except ValueError: -- Doesn't currently work\n",
    "        #    rating = None -- Doesn't currently work\n",
    "        ingredients = soup.findAll(\"li\", {\"class\": \"ingredients-item\"})\n",
    "        steps = soup.findAll(\"span\", {\"class\": \"recipe-directions__list--item\"})\n",
    "        name = soup.find(\"h1\", {\"class\": \"headline heading-content\"}).get_text().replace(\"®\", \"\")\n",
    "\n",
    "        direction_data = soup.find(\"div\", {\"class\": \"directions--section__steps\"})\n",
    "        #prep_time = direction_data.find(\"time\", {\"itemprop\": \"prepTime\"}).get_text() -- Doesn't currently work\n",
    "        #cook_time = direction_data.find(\"time\", {\"itemprop\": \"cookTime\"}).get_text() -- Doesn't currently work\n",
    "        #total_time = direction_data.find(\"time\", {\"itemprop\": \"totalTime\"}).get_text() -- Doesn't currently work\n",
    "                \n",
    "        data = {\n",
    "                #\"rating\": rating,\n",
    "                \"ingredients\": [],\n",
    "                \"steps\": [],\n",
    "                \"name\": name\n",
    "                #\"prep_time\": prep_time,\n",
    "                #\"cook_time\": cook_time,\n",
    "                #\"total_time\": total_time\n",
    "                }\n",
    "\n",
    "        for ingredient in ingredients:\n",
    "            str_ing = ingredient.find(\"input\", {\"class\": \"checkbox-list-input\"})['value']\n",
    "            if str_ing and str_ing != \"Add all ingredients to list\":\n",
    "                data[\"ingredients\"].append(str_ing.strip())\n",
    "\n",
    "        for step in steps:\n",
    "            str_step = step.get_text()\n",
    "            if str_step:\n",
    "                data[\"steps\"].append(str_step)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T13:31:47.745533Z",
     "start_time": "2020-08-24T13:31:42.759880Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query_options = {\n",
    "  \"wt\": \"duck curry\",         # Query keywords\n",
    "  \"ingIncl\": \"olives\",        # 'Must be included' ingrdients (optional)\n",
    "  \"ingExcl\": \"onions salad\",  # 'Must not be included' ingredients (optional)\n",
    "  \"sort\": \"re\"                # Sorting options : 're' for relevance, 'ra' for rating, 'p' for popular (optional)\n",
    "}\n",
    "query_result = AllRecipes.search(query_options)\n",
    "\n",
    "# Get :\n",
    "main_recipe_url = query_result[0]['url']\n",
    "detailed_recipe = AllRecipes.get(main_recipe_url)  # Get the details of the first returned recipe (most relevant in our case)\n",
    "\n",
    "# Display result :\n",
    "print(\"## %s :\" % detailed_recipe['name'])  # Name of the recipe\n",
    "\n",
    "for ingredient in detailed_recipe['ingredients']:  # List of ingredients\n",
    "    print(\"- %s\" % ingredient.strip())\n",
    "\n",
    "for step in detailed_recipe['steps']:  # List of cooking steps\n",
    "    print(\"# %s\" % step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Testing a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T13:29:54.034230Z",
     "start_time": "2020-08-24T13:29:51.485682Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query_options = {\n",
    "  \"wt\": \"beef\",         # Query keywords\n",
    "  \"ingIncl\": \"potato\",        # 'Must be included' ingrdients (optional)\n",
    "#  \"ingExcl\": \"onions salad\",  # 'Must not be included' ingredients (optional)\n",
    "  \"sort\": \"ra\"                # Sorting options : 're' for relevance, 'ra' for rating, 'p' for popular (optional)\n",
    "}\n",
    "query_result = AllRecipes.search(query_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T13:29:54.970597Z",
     "start_time": "2020-08-24T13:29:54.961568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T13:32:51.177963Z",
     "start_time": "2020-08-24T13:31:50.738039Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ingredient_database = []\n",
    "\n",
    "for result in query_result:\n",
    "    main_recipe_url = result['url']\n",
    "    print(main_recipe_url)\n",
    "    \n",
    "    ingredient_database.append(AllRecipes.get(main_recipe_url)['ingredients'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping until they kick me out (incl. amounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T08:08:43.438583Z",
     "start_time": "2020-08-25T08:08:43.434579Z"
    }
   },
   "outputs": [],
   "source": [
    "scraped_ingredients = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-25T08:08:44.670Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000,(0)\n",
      "7001,(1)\n",
      "7002,(2)\n",
      "7003,(3)\n",
      "7004,(4)\n",
      "7005,(5)\n",
      "7006,(6)\n",
      "7007,(7)\n",
      "7008,(8)\n",
      "7009,(9)\n",
      "7010,(10)\n",
      "7011,(11)\n",
      "7012,(12)\n",
      "7013,(13)\n",
      "7014,(14)\n",
      "7015,(15)\n",
      "7016,(16)\n",
      "7017,(17)\n",
      "7018,(18)\n",
      "7019,(19)\n",
      "7020,(20)\n",
      "7021,(21)\n",
      "7022,(22)\n",
      "7023,(23)\n",
      "7024,(24)\n",
      "7025,(25)\n",
      "7026,(26)\n",
      "7027,(27)\n",
      "7028,(28)\n",
      "-- 7029 (29)\n",
      "7030,(29)\n",
      "7031,(30)\n",
      "7032,(31)\n",
      "7033,(32)\n",
      "7034,(33)\n",
      "7035,(34)\n",
      "7036,(35)\n",
      "7037,(36)\n",
      "7038,(37)\n",
      "7039,(38)\n",
      "7040,(39)\n",
      "7041,(40)\n",
      "7042,(41)\n",
      "7043,(42)\n",
      "7044,(43)\n",
      "7045,(44)\n",
      "7046,(45)\n",
      "7047,(46)\n",
      "7048,(47)\n",
      "7049,(48)\n",
      "7050,(49)\n",
      "7051,(50)\n",
      "7052,(51)\n",
      "7053,(52)\n",
      "7054,(53)\n",
      "7055,(54)\n",
      "7056,(55)\n",
      "7057,(56)\n",
      "7058,(57)\n",
      "7059,(58)\n",
      "7060,(59)\n",
      "7061,(60)\n",
      "7062,(61)\n",
      "7063,(62)\n",
      "7064,(63)\n",
      "7065,(64)\n",
      "7066,(65)\n",
      "7067,(66)\n",
      "7068,(67)\n",
      "7069,(68)\n",
      "7070,(69)\n",
      "7071,(70)\n",
      "7072,(71)\n",
      "7073,(72)\n",
      "7074,(73)\n",
      "7075,(74)\n",
      "7076,(75)\n",
      "7077,(76)\n",
      "7078,(77)\n",
      "7079,(78)\n",
      "7080,(79)\n",
      "7081,(80)\n",
      "7082,(81)\n",
      "7083,(82)\n",
      "7084,(83)\n",
      "7085,(84)\n",
      "7086,(85)\n",
      "7087,(86)\n",
      "7088,(87)\n",
      "7089,(88)\n",
      "7090,(89)\n",
      "7091,(90)\n",
      "7092,(91)\n",
      "7093,(92)\n",
      "7094,(93)\n",
      "7095,(94)\n",
      "7096,(95)\n",
      "7097,(96)\n",
      "7098,(97)\n",
      "7099,(98)\n",
      "7100,(99)\n",
      "7101,(100)\n",
      "7102,(101)\n",
      "7103,(102)\n",
      "7104,(103)\n",
      "7105,(104)\n",
      "7106,(105)\n",
      "7107,(106)\n",
      "7108,(107)\n",
      "7109,(108)\n",
      "7110,(109)\n",
      "7111,(110)\n",
      "7112,(111)\n",
      "7113,(112)\n",
      "7114,(113)\n",
      "7115,(114)\n",
      "7116,(115)\n",
      "7117,(116)\n",
      "7118,(117)\n",
      "7119,(118)\n",
      "7120,(119)\n",
      "7121,(120)\n",
      "7122,(121)\n",
      "7123,(122)\n",
      "7124,(123)\n",
      "7125,(124)\n",
      "7126,(125)\n",
      "7127,(126)\n",
      "7128,(127)\n",
      "7129,(128)\n",
      "7130,(129)\n",
      "7131,(130)\n",
      "7132,(131)\n",
      "7133,(132)\n",
      "7134,(133)\n",
      "7135,(134)\n",
      "7136,(135)\n",
      "7137,(136)\n",
      "7138,(137)\n",
      "7139,(138)\n",
      "7140,(139)\n",
      "7141,(140)\n",
      "7142,(141)\n",
      "7143,(142)\n",
      "7144,(143)\n",
      "7145,(144)\n",
      "7146,(145)\n",
      "7147,(146)\n",
      "7148,(147)\n",
      "7149,(148)\n",
      "7150,(149)\n",
      "7151,(150)\n",
      "7152,(151)\n",
      "7153,(152)\n",
      "7154,(153)\n",
      "7155,(154)\n",
      "7156,(155)\n",
      "7157,(156)\n",
      "7158,(157)\n",
      "7159,(158)\n",
      "7160,(159)\n",
      "7161,(160)\n",
      "7162,(161)\n",
      "7163,(162)\n",
      "7164,(163)\n",
      "7165,(164)\n",
      "7166,(165)\n",
      "7167,(166)\n",
      "7168,(167)\n",
      "7169,(168)\n",
      "7170,(169)\n",
      "7171,(170)\n",
      "7172,(171)\n",
      "7173,(172)\n",
      "7174,(173)\n",
      "7175,(174)\n",
      "7176,(175)\n",
      "7177,(176)\n",
      "7178,(177)\n",
      "7179,(178)\n",
      "7180,(179)\n",
      "7181,(180)\n",
      "7182,(181)\n",
      "7183,(182)\n",
      "7184,(183)\n",
      "7185,(184)\n",
      "7186,(185)\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "i = 7000\n",
    "while j < 1000:\n",
    "    try:\n",
    "        url = f'https://www.allrecipes.com/recipe/{i}'\n",
    "        scraped_ingredients.append(AllRecipes.get(url)['ingredients'])\n",
    "        print(f'{i},({j})')\n",
    "        j += 1\n",
    "    except:\n",
    "        print(f'-- {i} ({j})')\n",
    "    i +=1\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-25T07:19:28.537Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(scraped_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-25T07:19:28.942Z"
    }
   },
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "\n",
    "cPickle.dump(scraped_ingredients, open('scraped_recipe_ingredients_1000.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-25T07:12:46.475Z"
    }
   },
   "outputs": [],
   "source": [
    "! ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "365.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
