{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated List-In || List-Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.202598Z",
     "start_time": "2020-08-27T14:08:24.779636Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yanni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yanni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\yanni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import _pickle as cPickle\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "import os.path\n",
    "\n",
    "import wikipedia\n",
    "import wikipediaapi\n",
    "wiki = wikipediaapi.Wikipedia('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.434106Z",
     "start_time": "2020-08-27T14:08:26.204572Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = cPickle.load(open('vectorizer.pk', 'rb'))\n",
    "df_wiki_similarities = cPickle.load(open('df_wiki_similarities.pk', 'rb'))\n",
    "\n",
    "api_key = \"AIzaSyB1AJ_3w-Yq1GhrkqQ6ZfSlASeeCRjT2Ns\"\n",
    "cse_id = \"dd94ab4664d1ce589\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.440117Z",
     "start_time": "2020-08-27T14:08:26.436079Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_ingredient_in_wikidata(ingredient):\n",
    "    found = ingredient in list(df_wiki_similarities.ingredient)\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.455117Z",
     "start_time": "2020-08-27T14:08:26.441655Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wiki_match(ingredient):\n",
    "\n",
    "    i_ix = list(df_wiki_similarities.ingredient).index(ingredient)\n",
    "\n",
    "    chosen_summ = df_wiki_similarities.summaries[i_ix]\n",
    "\n",
    "    sims = df_wiki_similarities.iloc[i_ix, 4:]\n",
    "\n",
    "    c_ix = pd.to_numeric(sims).argmax()\n",
    "\n",
    "    ingredient = df_wiki_similarities['ingredient'][i_ix]\n",
    "    category = df_wiki_similarities['ingredient'][c_ix]\n",
    "\n",
    "    return category, max(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.461120Z",
     "start_time": "2020-08-27T14:08:26.456154Z"
    }
   },
   "outputs": [],
   "source": [
    "def google_query(query, api_key, cse_id, **kwargs):\n",
    "\n",
    "    query_service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    query_results = query_service.cse().list(q=query, cx=cse_id,\n",
    "                                             **kwargs).execute()\n",
    "\n",
    "    return query_results['items']\n",
    "\n",
    "\n",
    "def get_google_cse_result(ingredient):\n",
    "\n",
    "    query = f'{ingredient} food'\n",
    "\n",
    "    my_results = google_query(query, api_key, cse_id, num=1)[0]\n",
    "\n",
    "    url = my_results['link']\n",
    "    url_base = os.path.basename(my_results['link'])\n",
    "\n",
    "    return ingredient, url, url_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.469145Z",
     "start_time": "2020-08-27T14:08:26.462116Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pageid_from_base(base):\n",
    "\n",
    "    info_url = f'https://en.wikipedia.org/w/index.php?title={base}&action=info'\n",
    "\n",
    "    req = urllib.request.Request(info_url)\n",
    "    req.add_header('Cookie', 'euConsent=true')\n",
    "    html_content = urllib.request.urlopen(req).read()\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    infosection = soup.find(\"script\")\n",
    "    pageid = infosection.decode().partition('wgArticleId\":')[2].partition(\n",
    "        ',')[0]\n",
    "\n",
    "    return pageid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.474117Z",
     "start_time": "2020-08-27T14:08:26.470117Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_summary_from_id(pageid):\n",
    "\n",
    "    pagesummary = wikipedia.page(pageid=pageid).summary\n",
    "\n",
    "    return pagesummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.483119Z",
     "start_time": "2020-08-27T14:08:26.477117Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process_summary(summary):\n",
    "\n",
    "    # Remove punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        summary = str(summary).replace(punctuation, '')\n",
    "\n",
    "    # Lower text\n",
    "    summary = summary.lower()\n",
    "\n",
    "    # Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    summary_tokenized = word_tokenize(summary)\n",
    "    text = [w for w in summary_tokenized if not w in stop_words]\n",
    "    summary = ' '.join(text)\n",
    "\n",
    "    # Remove digits\n",
    "    summary = ''.join([word for word in summary if not word.isdigit()])\n",
    "\n",
    "    # Keep only nouns\n",
    "    tokens = summary.split()\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    summary = [\n",
    "        word for word, pos in tags\n",
    "        if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')\n",
    "    ]\n",
    "\n",
    "    summary = ' '.join(summary)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.503144Z",
     "start_time": "2020-08-27T14:08:26.486117Z"
    }
   },
   "outputs": [],
   "source": [
    "catsums = list(df_wiki_similarities[df_wiki_similarities['ingr/cat'] == 'cat']\n",
    "               ['summaries'])\n",
    "cats = list(df_wiki_similarities[df_wiki_similarities['ingr/cat'] == 'cat']\n",
    "            ['ingredient'])\n",
    "catvectors = vectorizer.transform(catsums)\n",
    "\n",
    "def get_match_and_score(summary_vector):\n",
    "\n",
    "    scoreseries = []\n",
    "\n",
    "    for j, catsum in enumerate(catsums):\n",
    "\n",
    "        cosine_sum = 1 - spatial.distance.cosine(summary_vector.toarray(),\n",
    "                                                 catvectors[j, :].toarray())\n",
    "\n",
    "        scoreseries.append(cosine_sum)\n",
    "\n",
    "    matchscore = max(scoreseries)\n",
    "    match = cats[scoreseries.index(matchscore)]\n",
    "\n",
    "    return match, matchscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.509121Z",
     "start_time": "2020-08-27T14:08:26.504158Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_google_match(ingredient):\n",
    "\n",
    "    try:\n",
    "        ingredient, url, url_base = get_google_cse_result(ingredient)\n",
    "    except:\n",
    "        return 'nomatch', 0\n",
    "\n",
    "    pageid = get_pageid_from_base(url_base)\n",
    "\n",
    "    pagesummary = get_summary_from_id(pageid)\n",
    "\n",
    "    processed_summary = pre_process_summary(pagesummary)\n",
    "\n",
    "    summary_vector = vectorizer.transform([processed_summary])\n",
    "\n",
    "    match, matchscore = get_match_and_score(summary_vector)\n",
    "\n",
    "    return match, matchscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated functions incl. logical flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumed / predefined numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.515118Z",
     "start_time": "2020-08-27T14:08:26.511117Z"
    }
   },
   "outputs": [],
   "source": [
    "similarity_cutoff = 0.1\n",
    "no_match = 'No match found'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T14:08:26.525150Z",
     "start_time": "2020-08-27T14:08:26.516123Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_categories(df_parser_output, try_google=False):\n",
    "\n",
    "    matched_categories = []\n",
    "\n",
    "    list_of_ingredients = list(df_parser_output['name'])\n",
    "\n",
    "    for ingredient in list_of_ingredients:\n",
    "\n",
    "        if is_ingredient_in_wikidata(ingredient):\n",
    "\n",
    "            wikimatch, score = get_wiki_match(ingredient)\n",
    "\n",
    "            if score > similarity_cutoff:\n",
    "                match = wikimatch\n",
    "\n",
    "            elif try_google:\n",
    "                googlematch, score = get_google_match(ingredient)\n",
    "                if score > similarity_cutoff:\n",
    "                    match = googlematch\n",
    "                else:\n",
    "                    match = no_match\n",
    "\n",
    "            else:\n",
    "                match = no_match\n",
    "\n",
    "        elif try_google:\n",
    "\n",
    "            googlematch, score = get_google_match(ingredient)\n",
    "\n",
    "            if score > similarity_cutoff:\n",
    "                match = googlematch\n",
    "\n",
    "            else:\n",
    "                match = no_match\n",
    "\n",
    "        else:\n",
    "            match = no_match\n",
    "\n",
    "        matched_categories.append(match)\n",
    "\n",
    "    return matched_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T15:17:50.267682Z",
     "start_time": "2020-08-27T15:17:50.260646Z"
    }
   },
   "outputs": [],
   "source": [
    "names = [\n",
    "    'fish', 'flour', 'egg', 'egg egg', 'square semisweet chocolate',\n",
    "    'apple juice', 'all-purpose flour', 'allpurpose flour', 'salt',\n",
    "    'shortening', 'vegetable shortening', 'ramen noodles', 'buttermilk',\n",
    "    'coconut oil', 'almond milk', 'this is not an ingredient',\n",
    "    'THISISDEFINITELYNOTANINGREDIENT', 'ground chuck', 'fennel sausage',\n",
    "    'lettuce', 'avocado', 'white onion', 'scallions', 'garlic',\n",
    "    'graham crackers', 'bamboo shoots', 'lotus root', 'sweet potato', 'yam',\n",
    "    'cinnamon', 'kiwi', 'kiwi fruit', 'dragon fruit', 'orange', 'rice flour',\n",
    "    'yeast', 'vinegar', 'extra virgin olive oil','duck fat','aleppo pepper'\n",
    "]\n",
    "\n",
    "qtys = ['dummy_qty'] * len(names)\n",
    "units = ['dummy_unit'] * len(names)\n",
    "\n",
    "arr = np.array([qtys, units, names])\n",
    "\n",
    "testdf = pd.DataFrame(arr.T)\n",
    "testdf.columns = ['qty', 'unit', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T15:17:50.683492Z",
     "start_time": "2020-08-27T15:17:50.431465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fish (farmed)',\n",
       " 'Wheat & Rye (Bread)',\n",
       " 'Eggs',\n",
       " 'No match found',\n",
       " 'No match found',\n",
       " 'Apples',\n",
       " 'Wheat & Rye (Bread)',\n",
       " 'No match found',\n",
       " 'Other Vegetables',\n",
       " 'No match found',\n",
       " 'No match found',\n",
       " 'Pig Meat',\n",
       " 'No match found',\n",
       " 'Palm Oil',\n",
       " 'Soymilk',\n",
       " 'No match found',\n",
       " 'No match found',\n",
       " 'Bovine Meat (beef herd)',\n",
       " 'No match found',\n",
       " 'Other Vegetables',\n",
       " 'Berries & Grapes',\n",
       " 'Onions & leeks',\n",
       " 'Onions & leeks',\n",
       " 'Onions & leeks',\n",
       " 'No match found',\n",
       " 'Cassava',\n",
       " 'No match found',\n",
       " 'Potatoes',\n",
       " 'No match found',\n",
       " 'No match found',\n",
       " 'Poultry Meat',\n",
       " 'Berries & Grapes',\n",
       " 'No match found',\n",
       " 'Citrus Fruit',\n",
       " 'Rice',\n",
       " 'Wine',\n",
       " 'Olive Oil',\n",
       " 'Olive Oil',\n",
       " 'Poultry Meat',\n",
       " 'No match found']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_categories(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T15:18:13.590989Z",
     "start_time": "2020-08-27T15:17:50.739465Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fish (farmed)',\n",
       " 'Wheat & Rye (Bread)',\n",
       " 'Eggs',\n",
       " 'Eggs',\n",
       " 'Dark Chocolate',\n",
       " 'Apples',\n",
       " 'Wheat & Rye (Bread)',\n",
       " 'Maize (Meal)',\n",
       " 'Other Vegetables',\n",
       " 'No match found',\n",
       " 'No match found',\n",
       " 'Pig Meat',\n",
       " 'Milk',\n",
       " 'Palm Oil',\n",
       " 'Soymilk',\n",
       " 'No match found',\n",
       " 'No match found',\n",
       " 'Bovine Meat (beef herd)',\n",
       " 'Pig Meat',\n",
       " 'Other Vegetables',\n",
       " 'Berries & Grapes',\n",
       " 'Onions & leeks',\n",
       " 'Onions & leeks',\n",
       " 'Onions & leeks',\n",
       " 'No match found',\n",
       " 'Cassava',\n",
       " 'No match found',\n",
       " 'Potatoes',\n",
       " 'Root Vegetables',\n",
       " 'No match found',\n",
       " 'Poultry Meat',\n",
       " 'Berries & Grapes',\n",
       " 'Citrus Fruit',\n",
       " 'Citrus Fruit',\n",
       " 'Rice',\n",
       " 'Wine',\n",
       " 'Olive Oil',\n",
       " 'Olive Oil',\n",
       " 'Poultry Meat',\n",
       " 'No match found']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_categories(testdf, try_google=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Greenr",
   "language": "python",
   "name": "greenr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "366px",
    "left": "1457px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
